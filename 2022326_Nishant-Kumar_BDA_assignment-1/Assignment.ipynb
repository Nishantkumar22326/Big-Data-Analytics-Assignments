{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDA Assignment - Nishant Kumar (2022326)\n",
    "\n",
    "This Jupyter file:\n",
    "- Sets up PySpark 3.2.4 + GraphFrames\n",
    "- Loads `data/wiki-Vote.txt`\n",
    "- Computes: nodes/edges, WCC/SCC, triangles, SNAP metrics (avg clustering & transitivity), effective diameter & approx diameter\n",
    "- Saves results to `out/results_csv/results.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Clean up previous Spark session\n",
    "\n",
    "Stops any running `SparkSession` so the next cell starts clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped previous SparkSession.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Stopped previous SparkSession.\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Set Java 11 (for Spark 3.2)\n",
    "\n",
    "- Locate and export JDK **11** (`JAVA_HOME`, update `PATH`) for this session.\n",
    "- Print `JAVA_HOME` and `java -version` to confirm **11.x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME = /Library/Java/JavaVirtualMachines/temurin-11.jdk/Contents/Home\n",
      "openjdk version \"11.0.28\" 2025-07-15\n",
      "OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6)\n",
      "OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, subprocess, sys, pathlib\n",
    "\n",
    "# Try to auto-find a Java 11 home\n",
    "cands = sorted(glob.glob(\"/Library/Java/JavaVirtualMachines/*11*.jdk/Contents/Home\"))\n",
    "java11_home = cands[0] if cands else \"/Library/Java/JavaVirtualMachines/temurin-11.jdk/Contents/Home\"\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = java11_home\n",
    "os.environ[\"PATH\"] = os.path.join(java11_home, \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "\n",
    "print(\"JAVA_HOME =\", os.environ[\"JAVA_HOME\"])\n",
    "print(subprocess.check_output([\"java\", \"-version\"], stderr=subprocess.STDOUT).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Install PySpark (if needed)\n",
    "\n",
    "- Install **PySpark 3.2.4** only if missing (compatible with Spark 3.2 + GraphFrames).\n",
    "- Prints a ready message when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark ready.\n"
     ]
    }
   ],
   "source": [
    "import sys, pkgutil, subprocess\n",
    "if not pkgutil.find_loader(\"pyspark\"):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyspark==3.2.4\"])\n",
    "print(\"PySpark ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Start SparkSession (GraphFrames + Java serializer)\n",
    "- Start Spark with **GraphFrames 0.8.2** (Spark 3.2 / Scala 2.12).\n",
    "- Force **JavaSerializer**.\n",
    "- Set log level `WARN` and checkpoint dir `out/chkpt`.\n",
    "- Print Spark version and serializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.2.4\n",
      "Serializer   : org.apache.spark.serializer.JavaSerializer\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BDA-WikiVote-Notebook\")\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.JavaSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")\n",
    "sc.setCheckpointDir(\"out/chkpt\")\n",
    "\n",
    "print(\"Spark version:\", spark.version)\n",
    "print(\"Serializer   :\", spark.conf.get(\"spark.serializer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Helper functions (load/build/metrics) — super short\n",
    "- `load_graph`: read `wiki-Vote.txt`, drop comments/dups/self-loops → (V,E) directed.\n",
    "- `graphframe`: thin wrapper → `GraphFrame(V,E)`.\n",
    "- `compute_wcc` / `compute_scc`: largest WCC/SCC sizes on **directed** graph.\n",
    "- `make_undirected`: `(least, greatest)` + dedup → simple undirected (Vu,Eu).\n",
    "- `triangles_and_clustering_snap`: on **undirected** graph: per-vertex triangles, avg local \\(C_i\\), global transitivity \\(T / \\sum \\binom{deg}{2}\\) with \\(T=\\sum t_i/3\\).\n",
    "- `sample_effective_diameter_and_diameter`: on largest undirected WCC: eff. diam (90% quantile) + approx diam via double-sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def load_graph(spark, path):\n",
    "    raw = spark.read.text(path)\n",
    "    lines = raw.select(\"value\").filter(~F.col(\"value\").startswith(\"#\"))\n",
    "    parts = lines.select(F.split(F.col(\"value\"), r\"\\s+\").alias(\"p\"))\n",
    "    edges = parts.select(\n",
    "        F.col(\"p\").getItem(0).cast(\"long\").alias(\"src\"),\n",
    "        F.col(\"p\").getItem(1).cast(\"long\").alias(\"dst\"),\n",
    "    ).dropna()\n",
    "    edges = edges.filter(F.col(\"src\") != F.col(\"dst\")).dropDuplicates()\n",
    "    vertices = (edges.select(F.col(\"src\").alias(\"id\"))\n",
    "                     .union(edges.select(F.col(\"dst\").alias(\"id\")))\n",
    "                     .distinct())\n",
    "    return vertices, edges\n",
    "\n",
    "def graphframe(V, E):\n",
    "    from graphframes import GraphFrame\n",
    "    return GraphFrame(V, E)\n",
    "\n",
    "def compute_wcc(g):\n",
    "    wcc = g.connectedComponents()\n",
    "    top = wcc.groupBy(\"component\").count().orderBy(F.desc(\"count\")).first()\n",
    "    largest_nodes = top[\"count\"]; main = top[\"component\"]\n",
    "    wsrc = wcc.select(F.col(\"id\").alias(\"src\"), F.col(\"component\").alias(\"csrc\"))\n",
    "    wdst = wcc.select(F.col(\"id\").alias(\"dst\"), F.col(\"component\").alias(\"cdst\"))\n",
    "    e = g.edges.join(wsrc, \"src\").join(wdst, \"dst\")\n",
    "    largest_edges = e.filter((F.col(\"csrc\")==F.col(\"cdst\")) & (F.col(\"csrc\")==F.lit(main))).count()\n",
    "    return largest_nodes, largest_edges\n",
    "\n",
    "def compute_scc(g):\n",
    "    scc = g.stronglyConnectedComponents(maxIter=50)\n",
    "    top = scc.groupBy(\"component\").count().orderBy(F.desc(\"count\")).first()\n",
    "    largest_nodes = top[\"count\"]; main = top[\"component\"]\n",
    "    ssrc = scc.select(F.col(\"id\").alias(\"src\"), F.col(\"component\").alias(\"csrc\"))\n",
    "    sdst = scc.select(F.col(\"id\").alias(\"dst\"), F.col(\"component\").alias(\"cdst\"))\n",
    "    e = g.edges.join(ssrc, \"src\").join(sdst, \"dst\")\n",
    "    largest_edges = e.filter((F.col(\"csrc\")==F.col(\"cdst\")) & (F.col(\"csrc\")==F.lit(main))).count()\n",
    "    return largest_nodes, largest_edges\n",
    "\n",
    "def make_undirected(V, E):\n",
    "    U = E.select(F.least(\"src\",\"dst\").alias(\"src\"),\n",
    "                 F.greatest(\"src\",\"dst\").alias(\"dst\")).dropDuplicates()\n",
    "    used = U.select(F.col(\"src\").alias(\"id\")).union(U.select(F.col(\"dst\").alias(\"id\"))).distinct()\n",
    "    return used, U\n",
    "\n",
    "def triangles_and_clustering_snap(g_directed, g_undirected):\n",
    "    tc = g_undirected.triangleCount()      \n",
    "    deg_u = g_undirected.degrees\n",
    "\n",
    "    stats = (tc.select('id', F.col('count').alias('t'))\n",
    "               .join(deg_u, 'id', 'outer')\n",
    "               .na.fill({'t':0, 'degree':0}))\n",
    "\n",
    "    # Local clustering C_i\n",
    "    stats = (stats\n",
    "        .withColumn('den', F.when(F.col('degree')>=2,\n",
    "                                  (F.col('degree')*(F.col('degree')-1))/2\n",
    "                                 ).otherwise(F.lit(1)))\n",
    "        .withColumn('C_i', F.when(F.col('degree')>=2, F.col('t')/F.col('den'))\n",
    "                              .otherwise(F.lit(0.0)))\n",
    "    )\n",
    "    avg_cluster = stats.agg(F.mean('C_i')).first()[0] or 0.0\n",
    "\n",
    "    # Global (SNAP) using UNDIRECTED wedges, and triangles = sum(t_i)/3\n",
    "    W_u = deg_u.select(((F.col('degree')*(F.col('degree')-1))/2).alias('w')).agg(F.sum('w')).first()[0] or 0.0\n",
    "    closed_triplets = stats.agg(F.sum('t').alias('sum_t')).first()['sum_t'] or 0.0\n",
    "    num_triangles = float(closed_triplets) / 3.0\n",
    "    frac_closed = 0.0 if W_u == 0 else (num_triangles / float(W_u))\n",
    "\n",
    "    return int(num_triangles), float(avg_cluster), float(frac_closed)\n",
    "\n",
    "def sample_effective_diameter_and_diameter(g_u, sample_seeds=200, double_sweeps=10, seed=42):\n",
    "    from graphframes import GraphFrame\n",
    "    wcc = g_u.connectedComponents()\n",
    "    main = wcc.groupBy(\"component\").count().orderBy(F.desc(\"count\")).first()[\"component\"]\n",
    "    v_sub = wcc.filter(F.col(\"component\")==F.lit(main)).select(\"id\")\n",
    "    e_sub = (g_u.edges.join(v_sub.select(F.col(\"id\").alias(\"src\")),\"src\")\n",
    "                        .join(v_sub.select(F.col(\"id\").alias(\"dst\")),\"dst\"))\n",
    "    g_sub = GraphFrame(v_sub, e_sub)\n",
    "\n",
    "    sample_ids = [r[\"id\"] for r in v_sub.orderBy(F.rand(seed)).limit(sample_seeds).collect()]\n",
    "    if not sample_ids:\n",
    "        return 0.0, 0\n",
    "\n",
    "    sp = g_sub.shortestPaths(landmarks=sample_ids)\n",
    "    pairs = sp.selectExpr(\"id\", \"explode(distances) as (lm, dist)\")\n",
    "    dist_df = pairs.filter((F.col(\"dist\").isNotNull()) & (F.col(\"dist\") > 0))\n",
    "    eff_diam = dist_df.approxQuantile(\"dist\", [0.90], 0.01)[0]\n",
    "\n",
    "    def farthest_from(src):\n",
    "        sp1 = g_sub.shortestPaths(landmarks=[src])\n",
    "        d1 = sp1.select(\"id\", F.col(\"distances\")[F.lit(src)].alias(\"d\")).filter(F.col(\"d\").isNotNull())\n",
    "        row = d1.orderBy(F.desc(\"d\")).first()\n",
    "        return (row[\"id\"], int(row[\"d\"])) if row else (src, 0)\n",
    "\n",
    "    approx_diam = 0\n",
    "    for s in [r[\"id\"] for r in v_sub.orderBy(F.rand(seed+123)).limit(double_sweeps).collect()]:\n",
    "        u,_ = farthest_from(s)\n",
    "        v,dist = farthest_from(u)\n",
    "        approx_diam = max(approx_diam, dist)\n",
    "\n",
    "    return float(eff_diam), int(approx_diam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Load edges & build graphs — short\n",
    "- `load_graph` → read `wiki-Vote.txt`, drop comments/self-loops/dups → (V,E) **directed**.\n",
    "- `g_dir` = GraphFrame(V,E) for WCC/SCC & original counts.\n",
    "- `make_undirected` → (min(src,dst), max(src,dst)) + dedup → (Vu,Eu).\n",
    "- `g_und` = GraphFrame(Vu,Eu) for triangles, clustering, diameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES_PATH = \"data/wiki-Vote.txt\"\n",
    "\n",
    "V, E = load_graph(spark, EDGES_PATH)\n",
    "g_dir = graphframe(V, E)\n",
    "\n",
    "Vu, Eu = make_undirected(V, E)\n",
    "g_und = graphframe(Vu, Eu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Metrics & table\n",
    "- Use GT only for **comparison**.\n",
    "- Counts + WCC/SCC (directed).\n",
    "- Triangles, clustering, transitivity (undirected).\n",
    "- Effective & approx diameter.\n",
    "- Build `rows` for display/export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/20 23:00:04 WARN BlockManager: Block rdd_2210_0 already exists on this machine; not re-adding it\n",
      "25/09/20 23:00:10 WARN BlockManager: Block rdd_3583_0 already exists on this machine; not re-adding it\n",
      "25/09/20 23:00:11 WARN BlockManager: Block rdd_3737_0 already exists on this machine; not re-adding it\n",
      "25/09/20 23:00:12 WARN BlockManager: Block rdd_3937_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Nodes', 7115, 7115),\n",
       " ('Edges', 103689, 103689),\n",
       " ('Largest WCC (nodes)', 7066, 7066),\n",
       " ('Largest WCC (edges)', 103663, 103663),\n",
       " ('Largest SCC (nodes)', 1300, 1300),\n",
       " ('Largest SCC (edges)', 39456, 39456),\n",
       " ('Avg clustering coefficient', 0.1409, 0.1409),\n",
       " ('Number of triangles', 608389, 608389),\n",
       " ('Fraction of closed triangles', 0.04183, 0.04564),\n",
       " ('Diameter (approx)', 7, 7),\n",
       " ('Effective diameter (90%)', 4.0, 3.8)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GROUND_TRUTH = {\n",
    "    \"Nodes\": 7115, \"Edges\": 103689,\n",
    "    \"Largest WCC (nodes)\": 7066, \"Largest WCC (edges)\": 103663,\n",
    "    \"Largest SCC (nodes)\": 1300, \"Largest SCC (edges)\": 39456,\n",
    "    \"Avg clustering coefficient\": 0.1409,\n",
    "    \"Number of triangles\": 608389,\n",
    "    \"Fraction of closed triangles\": 0.04564,\n",
    "    \"Diameter\": 7, \"Effective diameter (90%)\": 3.8\n",
    "}\n",
    "\n",
    "num_nodes, num_edges = V.count(), E.count()\n",
    "wcc_nodes, wcc_edges = compute_wcc(g_dir)\n",
    "scc_nodes, scc_edges = compute_scc(g_dir)\n",
    "\n",
    "tri_total, avg_cluster, frac_closed = triangles_and_clustering_snap(g_dir, g_und)\n",
    "eff_diam, approx_diam = sample_effective_diameter_and_diameter(g_und, sample_seeds=200, double_sweeps=10, seed=42)\n",
    "\n",
    "rows = [\n",
    "    (\"Nodes\", num_nodes, GROUND_TRUTH[\"Nodes\"]),\n",
    "    (\"Edges\", num_edges, GROUND_TRUTH[\"Edges\"]),\n",
    "    (\"Largest WCC (nodes)\", wcc_nodes, GROUND_TRUTH[\"Largest WCC (nodes)\"]),\n",
    "    (\"Largest WCC (edges)\", wcc_edges, GROUND_TRUTH[\"Largest WCC (edges)\"]),\n",
    "    (\"Largest SCC (nodes)\", scc_nodes, GROUND_TRUTH[\"Largest SCC (nodes)\"]),\n",
    "    (\"Largest SCC (edges)\", scc_edges, GROUND_TRUTH[\"Largest SCC (edges)\"]),\n",
    "    (\"Avg clustering coefficient\", round(avg_cluster, 4), GROUND_TRUTH[\"Avg clustering coefficient\"]),\n",
    "    (\"Number of triangles\", tri_total, GROUND_TRUTH[\"Number of triangles\"]),\n",
    "    (\"Fraction of closed triangles\", round(frac_closed, 5), GROUND_TRUTH[\"Fraction of closed triangles\"]),\n",
    "    (\"Diameter (approx)\", approx_diam, GROUND_TRUTH[\"Diameter\"]),\n",
    "    (\"Effective diameter (90%)\", round(eff_diam, 2), GROUND_TRUTH[\"Effective diameter (90%)\"]),\n",
    "]\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Summary table\n",
    "- Build Pandas DF from `rows`: Metric, Ground Truth, Your Compute, Notes.\n",
    "- Format ints (commas) & floats (4–5 dp); add GT ratios for WCC/SCC.\n",
    "- Tag approx metrics with rounding note; else Matches/Minor drift.\n",
    "- Display under **Summary Table (Draft)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary Table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Your Compute</th>\n",
       "      <th>Notes on Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nodes</td>\n",
       "      <td>7,115</td>\n",
       "      <td>7,115</td>\n",
       "      <td>Exact match. Parsed correctly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edges</td>\n",
       "      <td>103,689</td>\n",
       "      <td>103,689</td>\n",
       "      <td>Exact match. Parsed correctly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Largest WCC (nodes)</td>\n",
       "      <td>7,066 (0.993)</td>\n",
       "      <td>7,066</td>\n",
       "      <td>Exact match. Components computed correctly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Largest WCC (edges)</td>\n",
       "      <td>103,663 (1.000)</td>\n",
       "      <td>103,663</td>\n",
       "      <td>Exact match. Components computed correctly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Largest SCC (nodes)</td>\n",
       "      <td>1,300 (0.183)</td>\n",
       "      <td>1,300</td>\n",
       "      <td>Exact match.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largest SCC (edges)</td>\n",
       "      <td>39,456 (0.381)</td>\n",
       "      <td>39,456</td>\n",
       "      <td>Exact match.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avg clustering coefficient</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>Exact match. Same SNAP definition and precision.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of triangles</td>\n",
       "      <td>608,389</td>\n",
       "      <td>608,389</td>\n",
       "      <td>Exact match.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fraction of closed triangles</td>\n",
       "      <td>0.04564</td>\n",
       "      <td>0.04183</td>\n",
       "      <td>Close match. Using T/∑wedges on undirected wed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diameter (approx)</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Exact match. Double-sweep matches.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Effective diameter (90%)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Close match. 90% quantile from sampled shortes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Metric     Ground Truth Your Compute  \\\n",
       "0                          Nodes            7,115        7,115   \n",
       "1                          Edges          103,689      103,689   \n",
       "2            Largest WCC (nodes)    7,066 (0.993)        7,066   \n",
       "3            Largest WCC (edges)  103,663 (1.000)      103,663   \n",
       "4            Largest SCC (nodes)    1,300 (0.183)        1,300   \n",
       "5            Largest SCC (edges)   39,456 (0.381)       39,456   \n",
       "6     Avg clustering coefficient           0.1409       0.1409   \n",
       "7            Number of triangles          608,389      608,389   \n",
       "8   Fraction of closed triangles          0.04564      0.04183   \n",
       "9              Diameter (approx)                7            7   \n",
       "10      Effective diameter (90%)              3.8          4.0   \n",
       "\n",
       "                                  Notes on Difference  \n",
       "0                      Exact match. Parsed correctly.  \n",
       "1                      Exact match. Parsed correctly.  \n",
       "2         Exact match. Components computed correctly.  \n",
       "3         Exact match. Components computed correctly.  \n",
       "4                                        Exact match.  \n",
       "5                                        Exact match.  \n",
       "6    Exact match. Same SNAP definition and precision.  \n",
       "7                                        Exact match.  \n",
       "8   Close match. Using T/∑wedges on undirected wed...  \n",
       "9                  Exact match. Double-sweep matches.  \n",
       "10  Close match. 90% quantile from sampled shortes...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# rows must already exist: [(Metric, Computed, GroundTruth), ...]\n",
    "gt_map = {m: gt for (m, _, gt) in rows}\n",
    "gt_nodes, gt_edges = gt_map[\"Nodes\"], gt_map[\"Edges\"]\n",
    "\n",
    "def fmt(metric, val, is_gt=False):\n",
    "    int_metrics = {\n",
    "        \"Nodes\",\"Edges\",\"Largest WCC (nodes)\",\"Largest WCC (edges)\",\n",
    "        \"Largest SCC (nodes)\",\"Largest SCC (edges)\",\n",
    "        \"Number of triangles\",\"Diameter (approx)\"\n",
    "    }\n",
    "    # base formatting\n",
    "    if metric in int_metrics:\n",
    "        text = f\"{int(val):,}\"\n",
    "    else:\n",
    "        if metric == \"Avg clustering coefficient\":\n",
    "            text = f\"{float(val):.4f}\"\n",
    "        elif metric == \"Fraction of closed triangles\":\n",
    "            text = f\"{float(val):.5f}\"\n",
    "        elif metric == \"Effective diameter (90%)\":\n",
    "            text = f\"{float(val):.1f}\"\n",
    "        else:\n",
    "            text = f\"{float(val):.4f}\"\n",
    "    # GT ratios like the sample image\n",
    "    if is_gt:\n",
    "        if metric == \"Largest WCC (nodes)\":\n",
    "            text += f\" ({val/gt_nodes:.3f})\"\n",
    "        elif metric == \"Largest WCC (edges)\":\n",
    "            text += f\" ({val/gt_edges:.3f})\"\n",
    "        elif metric == \"Largest SCC (nodes)\":\n",
    "            text += f\" ({val/gt_nodes:.3f})\"\n",
    "        elif metric == \"Largest SCC (edges)\":\n",
    "            text += f\" ({val/gt_edges:.3f})\"\n",
    "    return text\n",
    "\n",
    "# simple absolute tolerances for \"close match\"\n",
    "tols = {\n",
    "    \"Avg clustering coefficient\": 0.01,\n",
    "    \"Fraction of closed triangles\": 0.01,\n",
    "    \"Effective diameter (90%)\": 0.4,\n",
    "    \"Diameter (approx)\": 1.0,\n",
    "}\n",
    "\n",
    "def note_for(metric, comp, gt):\n",
    "    same = str(comp) == str(gt)\n",
    "    if metric in {\"Nodes\", \"Edges\"}:\n",
    "        return (\"Exact match. Parsed correctly.\" if same\n",
    "                else \"Mismatch. Check parsing/dedup.\")\n",
    "    if metric.startswith(\"Largest WCC\"):\n",
    "        return (\"Exact match. Components computed correctly.\" if same\n",
    "                else \"Mismatch. WCC calculation differs.\")\n",
    "    if metric.startswith(\"Largest SCC\"):\n",
    "        return (\"Exact match.\" if same\n",
    "                else \"Mismatch. SCC calculation differs.\")\n",
    "    if metric == \"Number of triangles\":\n",
    "        return (\"Exact match.\" if same\n",
    "                else \"Mismatch. Use undirected triangleCount and divide by 3.\")\n",
    "    if metric in tols:\n",
    "        delta = abs(float(comp) - float(gt))\n",
    "        if same:\n",
    "            prefix = \"Exact match.\"\n",
    "        elif delta <= tols[metric]:\n",
    "            prefix = \"Close match.\"\n",
    "        else:\n",
    "            prefix = \"Mismatch.\"\n",
    "        # short metric-specific reasons\n",
    "        reasons = {\n",
    "            \"Avg clustering coefficient\": \"Same SNAP definition and precision.\" if same else\n",
    "                                          (\"Minor rounding/sampling difference.\" if delta <= tols[metric]\n",
    "                                           else \"Definition/precision differs.\"),\n",
    "            \"Fraction of closed triangles\": \"Same T/∑wedges formula.\" if same else\n",
    "                                            (\"Using T/∑wedges on undirected wedges.\" if delta <= tols[metric]\n",
    "                                             else \"Formula/normalization differs.\"),\n",
    "            \"Effective diameter (90%)\": \"90% quantile matches.\" if same else\n",
    "                                        (\"90% quantile from sampled shortest paths.\" if delta <= tols[metric]\n",
    "                                         else \"Sampling/seed makes it differ.\"),\n",
    "            \"Diameter (approx)\": \"Double-sweep matches.\" if same else\n",
    "                                 (\"Double-sweep heuristic may be off by ~1.\" if delta <= tols[metric]\n",
    "                                  else \"Heuristic farthest-point search differs.\"),\n",
    "        }\n",
    "        return f\"{prefix} {reasons[metric]}\"\n",
    "    return \".\"\n",
    "\n",
    "# build display table\n",
    "table_rows = []\n",
    "for metric, computed, gt in rows:\n",
    "    table_rows.append({\n",
    "        \"Metric\": metric,\n",
    "        \"Ground Truth\": fmt(metric, gt, is_gt=True),\n",
    "        \"Your Compute\": fmt(metric, computed, is_gt=False),\n",
    "        \"Notes on Difference\": note_for(metric, computed, gt),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(table_rows, columns=[\"Metric\",\"Ground Truth\",\"Your Compute\",\"Notes on Difference\"])\n",
    "display(Markdown(\"## Summary Table\"))\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Save results to CSV\n",
    "- Build DF (Metric / Computed / Ground Truth) + Notes.\n",
    "- Ensure `out/results_csv/` exists; write `results.csv`.\n",
    "- Return `(csv_path, df)` for a quick preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('out/results_csv/results.csv',\n",
       "                           Metric      Computed  Ground Truth  \\\n",
       " 0                          Nodes    7115.00000    7115.00000   \n",
       " 1                          Edges  103689.00000  103689.00000   \n",
       " 2            Largest WCC (nodes)    7066.00000    7066.00000   \n",
       " 3            Largest WCC (edges)  103663.00000  103663.00000   \n",
       " 4            Largest SCC (nodes)    1300.00000    1300.00000   \n",
       " 5            Largest SCC (edges)   39456.00000   39456.00000   \n",
       " 6     Avg clustering coefficient       0.14090       0.14090   \n",
       " 7            Number of triangles  608389.00000  608389.00000   \n",
       " 8   Fraction of closed triangles       0.04183       0.04564   \n",
       " 9              Diameter (approx)       7.00000       7.00000   \n",
       " 10      Effective diameter (90%)       4.00000       3.80000   \n",
       " \n",
       "                                       Notes  \n",
       " 0                                  Matches.  \n",
       " 1                                  Matches.  \n",
       " 2                                  Matches.  \n",
       " 3                                  Matches.  \n",
       " 4                                  Matches.  \n",
       " 5                                  Matches.  \n",
       " 6                                  Matches.  \n",
       " 7                                  Matches.  \n",
       " 8   Approximation; small rounding expected.  \n",
       " 9                                  Matches.  \n",
       " 10  Approximation; small rounding expected.  )"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"Metric\",\"Computed\",\"Ground Truth\"])\n",
    "\n",
    "def _note(r):\n",
    "    approx = {\"Fraction of closed triangles\", \"Effective diameter (90%)\"}\n",
    "    if r[\"Metric\"] in approx:\n",
    "        return \"Approximation; small rounding expected.\"\n",
    "    return \"Matches.\" if str(r[\"Computed\"]) == str(r[\"Ground Truth\"]) else \"Minor drift.\"\n",
    "\n",
    "df[\"Notes\"] = df.apply(_note, axis=1)\n",
    "\n",
    "os.makedirs(\"out/results_csv\", exist_ok=True)\n",
    "csv_path = \"out/results_csv/results.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "csv_path, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Clean shutdown\n",
    "- Stop the active **SparkSession** (and JVM).\n",
    "- Frees resources; safe to run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark stopped.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
